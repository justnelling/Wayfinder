[Result(url='https://blog.samaltman.com/', id='https://blog.samaltman.com/', title='Sam Altman', score=0.20626166462898254, published_date='2022-04-06T00:00:00.000Z', author='', image='https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2779845/2_Q4jvs8eBye40c9jring6AP1eM/large_Screen_Shot_2022-04-06_at_11.12.20_AM.png', favicon='https://phthemes.s3.amazonaws.com/189/ocI2l2NFgWKLlp1H/images/favicon.ico?v=1496356566', subpages=None, extras=None, text='GPT-4o There are two things from our announcement today I wanted to highlight. First, a key part of our mission is to put very capable AI tools in the hands of people for free (or at a great price). I am very proud that we’ve made the best model in the world available for free in ChatGPT, without ads or anything like that. Our initial conception when we started OpenAI was that we’d create AI and use it to create all sorts of benefits for the world. Instead, it now looks like we’ll create AI and then other people will use it to create all sorts of amazing things that we all benefit from. We are a business and will find plenty of things to charge for, and that will help us provide free, outstanding AI service to (hopefully) billions of people. Second, the new voice (and video) mode is the best computer interface I’ve ever used. It feels like AI from the movies; and it’s still a bit surprising to me that it’s real. Getting to human-level response times and expressiveness turns out to be a big change. The original ChatGPT showed a hint of what was possible with language interfaces; this new thing feels viscerally different. It is fast, smart, fun, natural, and helpful. Talking to a computer has never felt really natural for me; now it does. As we add (optional) personalization, access to your information, the ability to take actions on your behalf, and more, I can really see an exciting future where we are able to use computers to do much more than ever before. Finally, huge thanks to the team that poured so much work into making this happen! What I Wish Someone Had Told Me Optimism, obsession, self-belief, raw horsepower and personal connections are how things get started. Cohesive teams, the right combination of calmness and urgency, and unreasonable commitment are how things get finished. Long-term orientation is in short supply; try not to worry about what people think in the short term, which will get easier over time. It is easier for a team to do a hard thing that really matters than to do an easy thing that doesn’t really matter; audacious ideas motivate people. Incentives are superpowers; set them carefully. Concentrate your resources on a small number of high-conviction bets; this is easy to say but evidently hard to do. You can delete more stuff than you think. Communicate clearly and concisely. Fight bullshit and bureaucracy every time you see it and get other people to fight it too. Do not let the org chart get in the way of people working productively together. Outcomes are what count; don’t let good process excuse bad results. Spend more time recruiting. Take risks on high-potential people with a fast rate of improvement. Look for evidence of getting stuff done in addition to intelligence. Superstars are even more valuable than they seem, but you have to evaluate people on their net impact on the performance of the organization. Fast iteration can make up for a lot; it’s usually ok to be wrong if you iterate quickly. Plans should be measured in decades, execution should be measured in weeks. Don’t fight the business equivalent of the laws of physics. Inspiration is perishable and life goes by fast. Inaction is a particularly insidious type of risk. Scale often has surprising emergent properties. Compounding exponentials are magic. In particular, you really want to build a business that gets a compounding advantage with scale. Get back up and keep going. Working with great people is one of the best parts of life. Helion Needs You Helion has been progressing even faster than I expected and is on pace in 2024 to 1) demonstrate Q &gt; 1 fusion and 2) resolve all questions needed to design a mass-producible fusion generator. The goals of the company are quite ambitious—clean, continuous energy for 1 cent per kilowatt-hour, and the ability to manufacture enough power plants to satisfy the current electrical demand of earth in a ten year period. If both things happen, it will transform the world. Abundant, clean, and radically inexpensive energy will elevate the quality of life for all of us—think about how much the cost of energy factors into what we do and use. Also, electricity at this price will allow us to do things like efficiently capture carbon (so although we’ll still rely on gasoline for awhile, it’ll be ok). Although Helion’s scientific progress of the past 8 years is phenomenal and necessary, it is not sufficient to rapidly get to this new energy economy. Helion now needs to figure out how to engineer machines that don’t break, how to build a factory and supply chain capable of manufacturing a machine every day, how to work with power grids and governments around the world, and more. The biggest input to the degree and speed of success at the company is now the talent of the people who join the team. Here are a few of the most critical jobs, but please don’t let the lack of a perfect fit deter you from applying. Electrical Engineer, Low Voltage: https://boards.greenhouse.io/helionenergy/jobs/4044506005 Electrical Engineer, Pulsed Power: https://boards.greenhouse.io/helionenergy/jobs/4044510005 Mechanical Engineer, Generator Systems: https://boards.greenhouse.io/helionenergy/jobs/4044522005 Manager of Mechanical Engineering: http s://boards.greenhouse.io/helionenergy/jobs/4044521005 DALL•E 2 Today we did a research launch of DALL•E 2, a new AI tool that can create and edit images from natural language instructions. Most importantly, we hope people love the tool and find it useful. For me, it’s the most delightful thing to play with we’ve created so far. I find it to be creativity-enhancing, helpful for many different situations, and fun in a way I haven’t felt from technology in a while. But I also think it’s noteworthy for a few reasons: 1) This is another example of what I think is going to be a new computer interface trend: you say what you want in natural language or with contextual clues, and the computer does it. We offer this for code and now image generation; both of these will get a lot better. But the same trend will happen in new ways until eventually it works for complex tasks—we can imagine an “AI office worker” that takes requests in natural language like a human does. 2) It sure does seem to “understand” concepts at many levels and how they relate to each other in sophisticated ways. 3) Copilot is a tool that helps coders be more productive, but still is very far from being able to create a full program. DALL•E 2 is a tool that will help artists and illustrators be more creative, but it can also create a “complete work”. This may be an early example of the impact AI on labor markets. Although I firmly believe AI will create lots of new jobs, and make many existing jobs much better by doing the boring bits well, I think it’s important to be honest that it’s increasingly going to make some jobs not very relevant (like technology frequently does). 4) It’s a reminder that predictions about AI are very difficult to make. A decade ago, the conventional wisdom was that AI would first impact physical labor, and then cognitive labor, and then maybe someday it could do creative work. It now looks like it’s going to go in the opposite order. 5) It’s an example of a world in which good ideas are the limit for what we can do, not specific skills. 6) Although the upsides are great, the model is powerful enough that it\'s easy to imagine the downsides. Hopefully this summer, we’ll do a product launch and people will be able to use it for all sorts of things. We wanted to start with a research launch to figure out how to minimize the downsides in collaboration with a larger group of researchers and artists, and to give people some time to adapt to the change—in general, we are believers in incremental deployment strategies. (Obviously the world already has Photoshop and we already know that images can be manipulated, for good and bad.) (A robot hand drawing, by DALL•E) Helion I’m delighted to be investing more in Helion . Helion is by far the most promising approach to fusion I’ve seen. David and Chris are two of the most impressive founders and builders (in the sense of building fusion machines, in addition to building companies!) I have ever met, and they have done something remarkable. When I first invested in them back in 2014, I was struck by the thoughtfulness of their plans about the scientific approach, the system design, cost optimizations, and the fuel cycle. And now, with a tiny fraction of the money spent on other fusion efforts but the culture of a startup, they and their team have built a generator that produces electricity. Helion has a clear path to net electricity by 2024, and has a long-term goal of delivering electricity for 1 cent per kilowatt-hour. (!) If this all works as we hope, we may have a path out of the climate crisis. Even though there are a lot of emissions that don’t come from electrical generation, we’d be able to use abundant energy to capture carbon and other greenhouses gases. And if we have much cheaper energy than ever before, we can do things that are difficult to imagine today. The cost of energy is one of the fundamental inputs in the costs of so much else; dramatically cheaper energy will lead to dramatically better quality of life for many people. The Strength of Being Misunderstood A founder recently asked me how to stop caring what other people think. I didn’t have an answer, and after reflecting on it more, I think it\'s the wrong question. Almost everyone cares what someone thinks (though caring what everyone thinks is definitely a mistake), and it\'s probably important. Caring too much makes you a sheep. But you need to be at least a little in tune with others to do something useful for them. It seems like there are two degrees of freedom: you can choose the people whose opinions you care about (and on what subjects), and you can choose the timescale you care about them on. Most people figure out the former [1] but the latter doesn’t seem to get much attention. The most impressive people I know care a lot about what people think, even people whose opinions they really shouldn’t value (a surprising numbers of them do something like keeping a folder of screenshots of tweets from haters). But what makes them unusual is that they generally care about other people’s opinions on a very long time horizon—as long as the history books get it right, they take some pride in letting the newspapers get it wrong. You should trade being short-term low-status for being long-term high-status, which most people seem unwilling to do. A common way this happens is by eventually being right about an important but deeply non-consensus bet. But there are lots of other ways–the key observation is that as long as you are right, being misunderstood by most people is a strength not a weakness. You and a small group of rebels get the space to solve an important problem that might otherwise not get solved. [1] In the memorable words of Coco Chanel, “I don’t care what you think about me. I don’t think about you at all.” PG and Jessica A lot of people want to replicate YC in some other industry or some other place or with some other strategy. In general, people seem to assume that: 1) although there was some degree of mystery or luck about how YC got going, it can’t be that hard, and 2) if you can get it off the ground, the network effects are self-sustaining. More YC-like things are good for the world; I generally try to be helpful. But almost none of them work. People are right about the self-sustaining part, but they can’t figure out how to get something going. The entire secret to YC getting going was PG and Jessica—there was no other magic trick. A few times a year, I end up in a conversation at a party where someone tells a story about how much PG changed their life—people speak with more gratitude than they do towards pretty much anyone else. Then everyone else agrees, YC founders and otherwise (non-YC founders might talk about an impactful essay or getting hired at a YC company). Jessica still sadly doesn’t get nearly the same degree of public credit, but the people who were around the early days of YC know the real story. What did they do? They took bets on unknown people and believed in them more than anyone had before. They set strong norms and fought back hard against bad behavior towards YC founders. They trusted their own convictions, were willing to do things their way, and were willing to be disliked by the existing power structures. They focused on the most important things, they worked hard, and they spent a huge amount of time 1:1 with people. They understood the value of community and long-term orientation. When YC was very small, it felt like a family. Perhaps most importantly, they built an ecosystem (thanks to Joe Gebbia for pointing this out). This is easy to talk about but hard to do, because it requires not being greedy. YC has left a lot of money on the table; other people have made more money from the ecosystem than YC has itself. This has cemented YC’s place—the benefits to the partners, alumni, current batch founders, Hacker News readers, Demo Day investors, and everyone else around YC is a huge part of what makes it work. I am not sure if any of this is particularly useful advice—none of it sounds that hard, and yet in the 15 years since, it hasn’t been close to replicated. But it seems worth trying. I am pretty sure no one has had a bigger total impact on the careers of people in the startup industry over that time period than the two of them. Researchers and Founders I spent many years working with founders and now I work with researchers. Although there are always individual exceptions, on average it’s surprising to me how different the best people in these groups are (including in some qualities that I had assumed were present in great people everywhere, like very high levels of self-belief). So I’ve been thinking about the ways they’re the same, because maybe there is something to learn about qualities of really effective people in general. The best people in both groups spend a lot of time reflecting on some version of the Hamming question—"what are the most important problems in your field, and why aren’t you working on them?” In general, no one reflects on this question enough, but the best people do it the most, and have the best ‘problem taste’, which is some combination of learning to think independently, reason about the future, and identify attack vectors. (This from John Schulman is worth reading: http://joschu.net/blog/opinionated-guide-ml-research.html ). They have a laser focus on the next step in front of them combined with long-term vision. Most people only have one or the other. They are extremely persistent and willing to work hard. As far as I can tell, there is no high-probability way to be very successful without this, and you should be suspicious of people who tell you otherwise unless you’d be happy having their career (and be especially suspicious if they worked hard themselves). They have a bias towards action and trying things, and they’re clear-eyed and honest about what is working and what isn’t (importantly, this goes both ways—I’m amazed by how many people will see something working and then not pursue it). They are creative idea-generators—a lot of the ideas may be terrible, but there is never a shortage. They really value autonomy and have a hard time with rules that they don’t think make sense. They are definitely not lemmings. Their motivations are often more complex than they seem—specifically, they are frequently very driven by genuine curiosity. Project Covalence Almost every company and non-profit working on COVID-19 that I offered to help asked for support with clinical trials—for companies focusing on developing novel drugs, vaccines, and diagnostics, rapidly spinning up trials is one of their biggest bottlenecks. Science remains the only way out of the COVID-19 crisis. Dramatically improving clinical trials, which are usually time-consuming and cost tens to hundreds of millions of dollars, is one of the highest-leverage ways to get out of it faster. The goal of this project, in collaboration with TrialSpark and Dr. Mark Fishman, is to offer much better clinical trial support to COVID-19 projects than anything that currently exists. Project Covalence’s platform, powered by TrialSpark, is uniquely optimized to support COVID-19 trials, which are ideally run in community settings or at the patient’s home to reduce the burden placed on hospitals and health systems. Project Covalence is well-positioned to tackle the operational and logistical challenges involved in launching such trials, and supports trial execution, 21 CFR Part 11 compliant remote data collection, telemedicine, biostatistics, sample kits for at-home specimen collection, and protocol writing. Researchers across academia and industry can leverage this shared infrastructure to rapidly launch their clinical trials. To facilitate coordination between studies, we will also be creating master protocols for platform studies to enable shared control arms and adaptive trial designs. If you’re interested in getting involved or have a trial that needs support, please get in touch at ProjectCovalence@trialspark.com or visit www.projectcovalence.com . Idea Generation The most common question prospective startup founders ask is how to get ideas for startups. The second most common question is if you have any ideas for their startup. But giving founders an idea almost always doesn’t work. Having ideas is among the most important qualities for a startup founder to have—you will need to generate lots of new ideas in the course of running a startup. YC once tried an experiment of funding seemingly good founders with no ideas. I think every company in this no-idea track failed. It turns out that good founders have lots of ideas about everything, so if you want to be a founder and can’t get an idea for a company, you should probably work on getting good at idea generation first. How do you do that? It’s important to be in the right kind of environment, and around the right kind of people. You want to be around people who have a good feel for the future, will entertain improbable plans, are optimistic, are smart in a creative way, and have a very high idea flux. These sorts of people tend to think without the constraints most people have, not have a lot of filters, and not care too much what other people think. The best ideas are fragile; most people don’t even start talking about them at all because they sound silly. Perhaps most of all, you want to be around people who don’t make you feel stupid for mentioning a bad idea, and who certainly never feel stupid for doing so themselves. Stay away from people who are world-weary and belittle your ambitions. Unfortunately, this is most of the world. But they hold on to the past, and you want to live in the future. You want to be able to project yourself 20 years into the future, and then think backwards from there. Trust yourself—20 years is a long time; it’s ok if your ideas about it seem pretty radical. Another way to do this is to think about the most important tectonic shifts happening right now. How is the world changing in fundamental ways? Can you identify a leading edge of change and an opportunity that it unlocks? The mobile phone explosion from 2008-2012 is the most recent significant example of this—we are overdue for another! In such a tectonic shift, the world changes so fast that the big incumbents usually get beaten by fast-moving and focused startups. (By the way, it’s useful to get good at differentiating between real trends and fake trends. A key differentiator is if the new platform is used a lot by a small number of people, or used a little by a lot of people.) Any time you can think of something that is possible this year and wasn’t possible last year, you should pay attention. You may have the seed of a great startup idea. This is especially true if next year will be too late. When you can say “I am sure this is going to happen, I’m just not sure if we’ll be the ones to do it”, that’s a good sign. Uber was like this for me—after the first time I used it, it was clear we weren’t going to be calling cabs for that much longer, but I wasn’t sure that Uber was going to win the space. A good question to ask yourself early in the process of thinking about an idea is “could this be huge if it worked?” There are many good ideas in the world, but few of them have the inherent advantages that can make a startup massively successful. Most businesses don’t generate a valuable accumulating advantage as they scale. Think early about why an idea might have that property. It’s obvious for Facebook or Airbnb, but it often exists in more subtle ways. It’s also important to think about what you’re well-suited for. This is hard to do with pure introspection; ideally you can ask a mentor or some people you’ve worked with what you’re particularly good at. I’ve come to believe that founder/company fit is as important as product/market fit. Finally, a good test for an idea is if you can articulate why most people think it’s a bad idea, but you understand what makes it good. This is from my notes for a talk I gave at a YC event in China in 2018. Thanks to Eric Migicovsky for encouraging me to post it! I wrote it when I thought mostly about startups; now I think mostly about AI development. I am struck by how much of it applies, particularly paragraphs 5-9.', highlights=None, highlight_scores=None, summary=None), Result(url='https://www.britannica.com/biography/Sam-Altman', id='https://www.britannica.com/biography/Sam-Altman', title='Sam Altman | Biography, OpenAI, Microsoft, & Facts', score=0.20504184067249298, published_date='2024-06-16T00:00:00.000Z', author='Erik Gregersen', image='https://cdn.britannica.com/77/252077-050-C6D4CCD8/openai-ceo-sam-altman-speaks-at-summit-in-san-francisco-nov-2023.jpg', favicon='https://www.britannica.com/favicon.png', subpages=None, extras=None, text='In full: Samuel Harris Altman Recent News Sam Altman (born April 22, 1985, Chicago , Illinois , U.S.) is an American entrepreneur who was president of the start-up accelerator Y Combinator from 2014 to 2019 and chief executive officer (CEO) of the artificial intelligence (AI) company OpenAI beginning in 2019. He has been compared to tech visionaries, including Steve Jobs and Bill Gates , and is known for his belief that artificial general intelligence (AGI) will be able to do anything that humans can. Early life Sam Altman was born in Chicago and moved as a young boy to the suburbs of St. Louis, Missouri. He showed an aptitude for numbers and computing at an early age. He knew he was gay but did not come out to his parents until he was a teenager. “Growing up gay in the Midwest in the 2000s was not the most awesome thing,” he said in a New Yorker interview in 2016. He attended John Burroughs , a elite prep school , where he announced to a school assembly that he was gay and encouraged teachers to post “Safe Space” placards in their classrooms in support of gay students. “What Sam did changed the school,” Altman’s college counselor said later in The New Yorker . Loopt and Y Combinator Altman attended Stanford University , where he studied computer science . He dropped out after two years, saying later that he had learned more playing poker with classmates than he had attending lectures by professors. He told The New York Times in 2023 that poker taught him “how to notice patterns in people over time, how to make decisions with very imperfect information….It’s a great game.” In 2005, after leaving Stanford, he founded Loopt, an app that allowed users to share their location with friends. Loopt was one of the first companies to receive funding from start-up accelerator Y Combinator. Although Loopt attracted partnerships with wireless carriers such as Sprint, it failed to attract users, and in 2012 it was acquired by the banking company Green Dot for $43 million. In 2011 Altman began working part-time as a partner at Y Combinator, and the next year he founded the venture fund Hydrazine Capital with his brother Max Altman. Y Combinator founders Paul Graham and Jessica Livingston asked Sam Altman to succeed Graham as president, and he accepted the position in 2014. Special 67% offer for students! Finish the semester strong with Britannica. Learn More Under Altman, Y Combinator cemented its reputation as the premier place for start-up founders to learn to build a successful company. Y Combinator assembles founders twice a year for a three-month program during which they learn how to turn their ideas into a useful business. Y Combinator also provides founders with $500,000 in funding in exchange for equity in their companies. By the time Altman stepped down as president in 2019, Y Combinator had helped about 1,900 companies, among them the room-rental service Airbnb, the delivery companies Instacart and DoorDash, the forum site Reddit , and the streaming platform Twitch . OpenAI: ChatGPT and turmoil In 2015 OpenAI was founded as a nonprofit organization to develop AI for the benefit of humanity. Altman and Tesla CEO Elon Musk were cochairs of the organization. OpenAI started with $1 billion in funding provided by Altman, Musk, American entrepreneur Peter Thiel , and the cloud computing company Amazon Web Services, among others. At the heart of the founding of OpenAI was the recognition of the power of artificial intelligence and the question of how that power would be used. In 2019 Altman compared the work of OpenAI to the Manhattan Project , which developed the first atomic bomb , telling The New York Times that the Manhattan Project had been “on the scale of OpenAI—the level of ambition we aspire to.” He is proud to point out that he and J. Robert Oppenheimer share a birthday. In 2018 Musk told Altman that Musk should run OpenAI so that it could catch up to Google. Altman turned Musk down, and Musk left OpenAI, which put the organization in a difficult position because Musk had been funding its work. Because AI development requires a large amount of computer resources, in 2019 OpenAI created a for-profit company that would fund OpenAI’s work but would be controlled by the nonprofit board. The for-profit part of OpenAI then partnered with the software company Microsoft to use its cloud computing service Azure, while Microsoft integrated OpenAI software into its products. Microsoft controlled 49 percent of OpenAI. OpenAI made great advances with large language models (LLMs), which are trained on copious amounts of written material to provide responses to users’ prompts, and with natural language processing (NLP), which computers use to respond to requests written in human language rather than in specialized programming languages. OpenAI’s family of LLMs, which use the GPT (Generative Pre-training Transformer) architecture, serve as the foundation of two popular products. DALL-E, introduced in 2021, takes a user’s prompt (e.g., “Klimt painting of cats wearing cowboy hats assembling a dinosaur skeleton”) and generates images on the basis of the prompt. OpenAI’s release of ChatGPT in late 2022 brought AI and the possibility of AGI to wider public attention. ChatGPT is software that responds to questions from users. The program’s quick responses to any subject and its impressive command of written English dazzled many, and, within five days, more than one million users had signed up. However, the fast development of AI as epitomized by ChatGPT concerned political leaders. In the months after ChatGPT’s release, U.S. Pres. Joe Biden issued an executive order about how the U.S. government would use AI, and British Prime Minister Rishi Sunak held an AI safety summit, attended by Altman, Musk, U.S. Vice Pres. Kamala Harris , and others, at which they discussed how to mitigate possible problems caused by AI. OpenAI’s ownership structure in which a nonprofit board governed a for-profit company laid bare the tensions surrounding AI—even in the tech-forward world of Silicon Valley . Would Altman’s vision lead to a world in which AI could do things beyond the imaginings of many in the early 2020s, or would it unleash capacity that could be used to the detriment of humanity? Altman thought the dire concerns were overstated and could be addressed over time. Ultimately, the debate exploded into a battle over corporate governance . On November 17, 2023, OpenAI’s board of directors announced that it had fired Altman as CEO because “he was not consistently candid in his communications with the board” and that board chair Greg Brockman would also step down. Days of tumult followed. Most OpenAI employees signed a letter to board members demanding their resignation and threatening to leave unless Altman and Brockman were reinstated. One member of the board, computer scientist Ilya Sutskever, signed the letter, saying on X (formerly Twitter) that he regretted his role in firing Altman. On November 20 Microsoft CEO Satya Nadella announced that Altman and Brockman would lead an AI research team at that company; however, negotiations continued between Altman and OpenAI’s board. On November 21 all but one board member agreed to resign, a new board was named, and Altman and Brockman returned to OpenAI. Altman’s conduct as CEO would also undergo an independent investigation. Erik Gregersen', highlights=None, highlight_scores=None, summary=None), Result(url='https://blog.samaltman.com/hard-startups', id='https://blog.samaltman.com/hard-startups', title='Hard Startups', score=0.2111477106809616, published_date=None, author='', image=None, favicon='https://phthemes.s3.amazonaws.com/189/ocI2l2NFgWKLlp1H/images/favicon.ico?v=1496356566', subpages=None, extras=None, text='The most counterintuitive secret about startups is that it’s often easier to succeed with a hard startup than an easy one. A hard startup requires a lot more money, time, coordination, or technological development than most startups. A good hard startup is one that will be valuable if it works (not all hard problems are worth solving!). I remember when Instagram started to get really popular—it felt like you couldn’t go a day without hearing about another photo sharing startup. That year, probably over 1,000 photo sharing startups were funded, while there were fewer than ten nuclear fusion startups in existence. Easy startups are easy to start but hard to make successful. The most precious commodity in the startup ecosystem right now is talented people, and for the most part talented people want to work on something they find meaningful. A startup eventually has to get a lot of people to join its quest. It’s usually reasonably easy to get the first five or ten people to join—you can offer large equity grants and areas of responsibility. But eventually, what you have to recruit with are the mission of the company, the likelihood of massive success, and the quality of the people there. [1] Few recruiting messages are as powerful (when true) as “the world needs this, it won’t happen any time soon if we don’t do it, and we are much less likely to succeed if you don’t join.” There is a derivative of the Peter Principle at play here—your startup will rise to the level where it can no longer attract enough talented people. (This sometimes holds true for careers too—the limiting factor for many careers eventually becomes how many talented people you know and can get to work with you.) An easy startup is a headwind; a hard startup is a tailwind. If people care about your success because you seem committed to doing something significant, it’s a background force helping you with hiring, advice, partnerships, fundraising, etc. Part of the magic of Silicon Valley is that people default to taking you seriously if you’re willing to be serious—they’ve learned it’s a very expensive mistake, in aggregate, not to. If you want to start a company working on a better way to build homes, gene editing, artificial general intelligence, a new education system, or carbon sequestration, you may actually be able to get it funded, even if you don’t have a degree or much experience. Let yourself become more ambitious—figure out the most interesting version of where what you’re working on could go. Then talk about that big vision and work relentlessly towards it, but always have a reasonable next step. You don’t want step one to be incorporating the company and step two to be going to Mars. Be willing to make a very long-term commitment to what you’re doing. Most people aren’t, which is part of the reason they pick “easy” startups. In a world of compounding advantages where most people are operating on a 3 year timeframe and you’re operating on a 10 year timeframe, you’ll have a very large edge. Thanks to Luke Miles for reviewing drafts of this. [1] Another solution to this problem is to think about startups that can become quite successful with less than ten people. As compensation packages from the giant tech companies continue to increase, I suspect this will become a trend.', highlights=None, highlight_scores=None, summary=None), Result(url='https://blog.samaltman.com/', id='https://blog.samaltman.com/', title='Sam Altman', score=0.203726664185524, published_date='2022-04-06T00:00:00.000Z', author='', image='https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2779845/2_Q4jvs8eBye40c9jring6AP1eM/large_Screen_Shot_2022-04-06_at_11.12.20_AM.png', favicon='https://phthemes.s3.amazonaws.com/189/ocI2l2NFgWKLlp1H/images/favicon.ico?v=1496356566', subpages=None, extras=None, text='GPT-4o There are two things from our announcement today I wanted to highlight. First, a key part of our mission is to put very capable AI tools in the hands of people for free (or at a great price). I am very proud that we’ve made the best model in the world available for free in ChatGPT, without ads or anything like that. Our initial conception when we started OpenAI was that we’d create AI and use it to create all sorts of benefits for the world. Instead, it now looks like we’ll create AI and then other people will use it to create all sorts of amazing things that we all benefit from. We are a business and will find plenty of things to charge for, and that will help us provide free, outstanding AI service to (hopefully) billions of people. Second, the new voice (and video) mode is the best computer interface I’ve ever used. It feels like AI from the movies; and it’s still a bit surprising to me that it’s real. Getting to human-level response times and expressiveness turns out to be a big change. The original ChatGPT showed a hint of what was possible with language interfaces; this new thing feels viscerally different. It is fast, smart, fun, natural, and helpful. Talking to a computer has never felt really natural for me; now it does. As we add (optional) personalization, access to your information, the ability to take actions on your behalf, and more, I can really see an exciting future where we are able to use computers to do much more than ever before. Finally, huge thanks to the team that poured so much work into making this happen! What I Wish Someone Had Told Me Optimism, obsession, self-belief, raw horsepower and personal connections are how things get started. Cohesive teams, the right combination of calmness and urgency, and unreasonable commitment are how things get finished. Long-term orientation is in short supply; try not to worry about what people think in the short term, which will get easier over time. It is easier for a team to do a hard thing that really matters than to do an easy thing that doesn’t really matter; audacious ideas motivate people. Incentives are superpowers; set them carefully. Concentrate your resources on a small number of high-conviction bets; this is easy to say but evidently hard to do. You can delete more stuff than you think. Communicate clearly and concisely. Fight bullshit and bureaucracy every time you see it and get other people to fight it too. Do not let the org chart get in the way of people working productively together. Outcomes are what count; don’t let good process excuse bad results. Spend more time recruiting. Take risks on high-potential people with a fast rate of improvement. Look for evidence of getting stuff done in addition to intelligence. Superstars are even more valuable than they seem, but you have to evaluate people on their net impact on the performance of the organization. Fast iteration can make up for a lot; it’s usually ok to be wrong if you iterate quickly. Plans should be measured in decades, execution should be measured in weeks. Don’t fight the business equivalent of the laws of physics. Inspiration is perishable and life goes by fast. Inaction is a particularly insidious type of risk. Scale often has surprising emergent properties. Compounding exponentials are magic. In particular, you really want to build a business that gets a compounding advantage with scale. Get back up and keep going. Working with great people is one of the best parts of life. Helion Needs You Helion has been progressing even faster than I expected and is on pace in 2024 to 1) demonstrate Q &gt; 1 fusion and 2) resolve all questions needed to design a mass-producible fusion generator. The goals of the company are quite ambitious—clean, continuous energy for 1 cent per kilowatt-hour, and the ability to manufacture enough power plants to satisfy the current electrical demand of earth in a ten year period. If both things happen, it will transform the world. Abundant, clean, and radically inexpensive energy will elevate the quality of life for all of us—think about how much the cost of energy factors into what we do and use. Also, electricity at this price will allow us to do things like efficiently capture carbon (so although we’ll still rely on gasoline for awhile, it’ll be ok). Although Helion’s scientific progress of the past 8 years is phenomenal and necessary, it is not sufficient to rapidly get to this new energy economy. Helion now needs to figure out how to engineer machines that don’t break, how to build a factory and supply chain capable of manufacturing a machine every day, how to work with power grids and governments around the world, and more. The biggest input to the degree and speed of success at the company is now the talent of the people who join the team. Here are a few of the most critical jobs, but please don’t let the lack of a perfect fit deter you from applying. Electrical Engineer, Low Voltage: https://boards.greenhouse.io/helionenergy/jobs/4044506005 Electrical Engineer, Pulsed Power: https://boards.greenhouse.io/helionenergy/jobs/4044510005 Mechanical Engineer, Generator Systems: https://boards.greenhouse.io/helionenergy/jobs/4044522005 Manager of Mechanical Engineering: http s://boards.greenhouse.io/helionenergy/jobs/4044521005 DALL•E 2 Today we did a research launch of DALL•E 2, a new AI tool that can create and edit images from natural language instructions. Most importantly, we hope people love the tool and find it useful. For me, it’s the most delightful thing to play with we’ve created so far. I find it to be creativity-enhancing, helpful for many different situations, and fun in a way I haven’t felt from technology in a while. But I also think it’s noteworthy for a few reasons: 1) This is another example of what I think is going to be a new computer interface trend: you say what you want in natural language or with contextual clues, and the computer does it. We offer this for code and now image generation; both of these will get a lot better. But the same trend will happen in new ways until eventually it works for complex tasks—we can imagine an “AI office worker” that takes requests in natural language like a human does. 2) It sure does seem to “understand” concepts at many levels and how they relate to each other in sophisticated ways. 3) Copilot is a tool that helps coders be more productive, but still is very far from being able to create a full program. DALL•E 2 is a tool that will help artists and illustrators be more creative, but it can also create a “complete work”. This may be an early example of the impact AI on labor markets. Although I firmly believe AI will create lots of new jobs, and make many existing jobs much better by doing the boring bits well, I think it’s important to be honest that it’s increasingly going to make some jobs not very relevant (like technology frequently does). 4) It’s a reminder that predictions about AI are very difficult to make. A decade ago, the conventional wisdom was that AI would first impact physical labor, and then cognitive labor, and then maybe someday it could do creative work. It now looks like it’s going to go in the opposite order. 5) It’s an example of a world in which good ideas are the limit for what we can do, not specific skills. 6) Although the upsides are great, the model is powerful enough that it\'s easy to imagine the downsides. Hopefully this summer, we’ll do a product launch and people will be able to use it for all sorts of things. We wanted to start with a research launch to figure out how to minimize the downsides in collaboration with a larger group of researchers and artists, and to give people some time to adapt to the change—in general, we are believers in incremental deployment strategies. (Obviously the world already has Photoshop and we already know that images can be manipulated, for good and bad.) (A robot hand drawing, by DALL•E) Helion I’m delighted to be investing more in Helion . Helion is by far the most promising approach to fusion I’ve seen. David and Chris are two of the most impressive founders and builders (in the sense of building fusion machines, in addition to building companies!) I have ever met, and they have done something remarkable. When I first invested in them back in 2014, I was struck by the thoughtfulness of their plans about the scientific approach, the system design, cost optimizations, and the fuel cycle. And now, with a tiny fraction of the money spent on other fusion efforts but the culture of a startup, they and their team have built a generator that produces electricity. Helion has a clear path to net electricity by 2024, and has a long-term goal of delivering electricity for 1 cent per kilowatt-hour. (!) If this all works as we hope, we may have a path out of the climate crisis. Even though there are a lot of emissions that don’t come from electrical generation, we’d be able to use abundant energy to capture carbon and other greenhouses gases. And if we have much cheaper energy than ever before, we can do things that are difficult to imagine today. The cost of energy is one of the fundamental inputs in the costs of so much else; dramatically cheaper energy will lead to dramatically better quality of life for many people. The Strength of Being Misunderstood A founder recently asked me how to stop caring what other people think. I didn’t have an answer, and after reflecting on it more, I think it\'s the wrong question. Almost everyone cares what someone thinks (though caring what everyone thinks is definitely a mistake), and it\'s probably important. Caring too much makes you a sheep. But you need to be at least a little in tune with others to do something useful for them. It seems like there are two degrees of freedom: you can choose the people whose opinions you care about (and on what subjects), and you can choose the timescale you care about them on. Most people figure out the former [1] but the latter doesn’t seem to get much attention. The most impressive people I know care a lot about what people think, even people whose opinions they really shouldn’t value (a surprising numbers of them do something like keeping a folder of screenshots of tweets from haters). But what makes them unusual is that they generally care about other people’s opinions on a very long time horizon—as long as the history books get it right, they take some pride in letting the newspapers get it wrong. You should trade being short-term low-status for being long-term high-status, which most people seem unwilling to do. A common way this happens is by eventually being right about an important but deeply non-consensus bet. But there are lots of other ways–the key observation is that as long as you are right, being misunderstood by most people is a strength not a weakness. You and a small group of rebels get the space to solve an important problem that might otherwise not get solved. [1] In the memorable words of Coco Chanel, “I don’t care what you think about me. I don’t think about you at all.” PG and Jessica A lot of people want to replicate YC in some other industry or some other place or with some other strategy. In general, people seem to assume that: 1) although there was some degree of mystery or luck about how YC got going, it can’t be that hard, and 2) if you can get it off the ground, the network effects are self-sustaining. More YC-like things are good for the world; I generally try to be helpful. But almost none of them work. People are right about the self-sustaining part, but they can’t figure out how to get something going. The entire secret to YC getting going was PG and Jessica—there was no other magic trick. A few times a year, I end up in a conversation at a party where someone tells a story about how much PG changed their life—people speak with more gratitude than they do towards pretty much anyone else. Then everyone else agrees, YC founders and otherwise (non-YC founders might talk about an impactful essay or getting hired at a YC company). Jessica still sadly doesn’t get nearly the same degree of public credit, but the people who were around the early days of YC know the real story. What did they do? They took bets on unknown people and believed in them more than anyone had before. They set strong norms and fought back hard against bad behavior towards YC founders. They trusted their own convictions, were willing to do things their way, and were willing to be disliked by the existing power structures. They focused on the most important things, they worked hard, and they spent a huge amount of time 1:1 with people. They understood the value of community and long-term orientation. When YC was very small, it felt like a family. Perhaps most importantly, they built an ecosystem (thanks to Joe Gebbia for pointing this out). This is easy to talk about but hard to do, because it requires not being greedy. YC has left a lot of money on the table; other people have made more money from the ecosystem than YC has itself. This has cemented YC’s place—the benefits to the partners, alumni, current batch founders, Hacker News readers, Demo Day investors, and everyone else around YC is a huge part of what makes it work. I am not sure if any of this is particularly useful advice—none of it sounds that hard, and yet in the 15 years since, it hasn’t been close to replicated. But it seems worth trying. I am pretty sure no one has had a bigger total impact on the careers of people in the startup industry over that time period than the two of them. Researchers and Founders I spent many years working with founders and now I work with researchers. Although there are always individual exceptions, on average it’s surprising to me how different the best people in these groups are (including in some qualities that I had assumed were present in great people everywhere, like very high levels of self-belief). So I’ve been thinking about the ways they’re the same, because maybe there is something to learn about qualities of really effective people in general. The best people in both groups spend a lot of time reflecting on some version of the Hamming question—"what are the most important problems in your field, and why aren’t you working on them?” In general, no one reflects on this question enough, but the best people do it the most, and have the best ‘problem taste’, which is some combination of learning to think independently, reason about the future, and identify attack vectors. (This from John Schulman is worth reading: http://joschu.net/blog/opinionated-guide-ml-research.html ). They have a laser focus on the next step in front of them combined with long-term vision. Most people only have one or the other. They are extremely persistent and willing to work hard. As far as I can tell, there is no high-probability way to be very successful without this, and you should be suspicious of people who tell you otherwise unless you’d be happy having their career (and be especially suspicious if they worked hard themselves). They have a bias towards action and trying things, and they’re clear-eyed and honest about what is working and what isn’t (importantly, this goes both ways—I’m amazed by how many people will see something working and then not pursue it). They are creative idea-generators—a lot of the ideas may be terrible, but there is never a shortage. They really value autonomy and have a hard time with rules that they don’t think make sense. They are definitely not lemmings. Their motivations are often more complex than they seem—specifically, they are frequently very driven by genuine curiosity. Project Covalence Almost every company and non-profit working on COVID-19 that I offered to help asked for support with clinical trials—for companies focusing on developing novel drugs, vaccines, and diagnostics, rapidly spinning up trials is one of their biggest bottlenecks. Science remains the only way out of the COVID-19 crisis. Dramatically improving clinical trials, which are usually time-consuming and cost tens to hundreds of millions of dollars, is one of the highest-leverage ways to get out of it faster. The goal of this project, in collaboration with TrialSpark and Dr. Mark Fishman, is to offer much better clinical trial support to COVID-19 projects than anything that currently exists. Project Covalence’s platform, powered by TrialSpark, is uniquely optimized to support COVID-19 trials, which are ideally run in community settings or at the patient’s home to reduce the burden placed on hospitals and health systems. Project Covalence is well-positioned to tackle the operational and logistical challenges involved in launching such trials, and supports trial execution, 21 CFR Part 11 compliant remote data collection, telemedicine, biostatistics, sample kits for at-home specimen collection, and protocol writing. Researchers across academia and industry can leverage this shared infrastructure to rapidly launch their clinical trials. To facilitate coordination between studies, we will also be creating master protocols for platform studies to enable shared control arms and adaptive trial designs. If you’re interested in getting involved or have a trial that needs support, please get in touch at ProjectCovalence@trialspark.com or visit www.projectcovalence.com . Idea Generation The most common question prospective startup founders ask is how to get ideas for startups. The second most common question is if you have any ideas for their startup. But giving founders an idea almost always doesn’t work. Having ideas is among the most important qualities for a startup founder to have—you will need to generate lots of new ideas in the course of running a startup. YC once tried an experiment of funding seemingly good founders with no ideas. I think every company in this no-idea track failed. It turns out that good founders have lots of ideas about everything, so if you want to be a founder and can’t get an idea for a company, you should probably work on getting good at idea generation first. How do you do that? It’s important to be in the right kind of environment, and around the right kind of people. You want to be around people who have a good feel for the future, will entertain improbable plans, are optimistic, are smart in a creative way, and have a very high idea flux. These sorts of people tend to think without the constraints most people have, not have a lot of filters, and not care too much what other people think. The best ideas are fragile; most people don’t even start talking about them at all because they sound silly. Perhaps most of all, you want to be around people who don’t make you feel stupid for mentioning a bad idea, and who certainly never feel stupid for doing so themselves. Stay away from people who are world-weary and belittle your ambitions. Unfortunately, this is most of the world. But they hold on to the past, and you want to live in the future. You want to be able to project yourself 20 years into the future, and then think backwards from there. Trust yourself—20 years is a long time; it’s ok if your ideas about it seem pretty radical. Another way to do this is to think about the most important tectonic shifts happening right now. How is the world changing in fundamental ways? Can you identify a leading edge of change and an opportunity that it unlocks? The mobile phone explosion from 2008-2012 is the most recent significant example of this—we are overdue for another! In such a tectonic shift, the world changes so fast that the big incumbents usually get beaten by fast-moving and focused startups. (By the way, it’s useful to get good at differentiating between real trends and fake trends. A key differentiator is if the new platform is used a lot by a small number of people, or used a little by a lot of people.) Any time you can think of something that is possible this year and wasn’t possible last year, you should pay attention. You may have the seed of a great startup idea. This is especially true if next year will be too late. When you can say “I am sure this is going to happen, I’m just not sure if we’ll be the ones to do it”, that’s a good sign. Uber was like this for me—after the first time I used it, it was clear we weren’t going to be calling cabs for that much longer, but I wasn’t sure that Uber was going to win the space. A good question to ask yourself early in the process of thinking about an idea is “could this be huge if it worked?” There are many good ideas in the world, but few of them have the inherent advantages that can make a startup massively successful. Most businesses don’t generate a valuable accumulating advantage as they scale. Think early about why an idea might have that property. It’s obvious for Facebook or Airbnb, but it often exists in more subtle ways. It’s also important to think about what you’re well-suited for. This is hard to do with pure introspection; ideally you can ask a mentor or some people you’ve worked with what you’re particularly good at. I’ve come to believe that founder/company fit is as important as product/market fit. Finally, a good test for an idea is if you can articulate why most people think it’s a bad idea, but you understand what makes it good. This is from my notes for a talk I gave at a YC event in China in 2018. Thanks to Eric Migicovsky for encouraging me to post it! I wrote it when I thought mostly about startups; now I think mostly about AI development. I am struck by how much of it applies, particularly paragraphs 5-9.', highlights=None, highlight_scores=None, summary=None), Result(url='https://www.forbes.com/sites/johnwerner/2024/11/17/sam-altman-speaks-on-tech-progress/', id='https://www.forbes.com/sites/johnwerner/2024/11/17/sam-altman-speaks-on-tech-progress/', title='Sam Altman Speaks On Tech Progress - Forbes', score=None, published_date='2024-11-17T00:00:00.000Z', author='John Werner', image=None, favicon=None, subpages=None, extras=None, text="AFP via Getty Images Speaking at OpenAI’s Dev Day event, Sam Altman went over a lot of aspects of what’s happening right now with OpenAI’s products and other cutting-edge AI models, in answering questions from Harry Stebbings, founder of 20VC. One interesting aspect of what’s possible with new reasoning models and other systems is AI’s ability to code: throughout his interview, Altman kept talking about how much progress we can make toward no-code solutions. Referring to the “next turn of the model crank,” he suggested that there are parts of the industry that newer models will steamroll, where companies that are making tweaks around the margins are likely to lose out. “We believe that we are on a quite steep trajectory of improvement, and that the current shortcomings of the models today will just be taken care of by future generations. And I would encourage people to be aligned with that.” Altman suggested companies should be focused on creating new products and services, not trying to fix problems that may be obsolete in as little as a year or less. One of the surprising things, he said, that happened toward the beginning of this march toward better models is that companies were betting against the models themselves getting better. That trend, he said, has now been inverted as people realize how great systems are and how rapidly they improve. “I felt like 95% of people were betting against the models, and 5% of people betting for the models getting better,” he said. “I think that's now reversed. I think people have … internalized the rate of improvement, and have heard us what we intend to do. So it no longer seems to be such an issue, but it was something we used to fret about a lot.” Agentic Artificial Intelligence: What Does It Mean? Later in the interview, Altman went on to talk to the nature of what’s called ‘agentic’ AI. We’re hearing a lot about this now as the systems become able to perform tasks in human-like ways. Altman defined agentic AI as something that a human can give a “long-duration task” to, letting it operate with minimal supervision. He also gave a practical example – rather than just booking your reservation at a restaurant, he suggested these systems might be able to check with 200 or 300 restaurants to find the optimal diet and cuisine time for dining, etc., or alternately, become your “senior coworker” who can help reinvent business processes on the fly. That led to questions about the replacement of human labor. Much of these predictions, he said, is speculation, because we don’t know exactly how things are going to shake out. The Value of Training Discussing the training of models, Altman admitted that it may be hard for some companies to get return on investment, but he pointed to situations where things like a positive cumulative effect of multiple model trainings will justify investment for enterprise. Open AI, he noted, is fairly insulated, because it has ChatGPT with legions of users, so company leaders don’t have to worry about whether they’re getting enough bang for the buck out of their training or any other process. Other companies, he said, may have to operate from a standpoint of real analysis of the industry itself. As for how to do this kind of planning, Altman provided the following, interjecting some of his own experience: “How do you balance what has to happen today, or next month, with the long-range plans, … to execute in a year or two years, with build out (or) compute, or things that are more normal, like planning ahead enough for like office space in the city of San Francisco, … I think there was either no playbook for this, or someone had a secret playbook they didn't give me for all of this, like we've all just sort of fumbled our way through this, but there's been a lot to learn on the fly.” He also enumerated some other problems that companies have mostly been able to conquer as advances continue: bad model behaviors, failed paradigms, intractable problems. Invoking the language of the Beatles, he suggested it has been a “long and winding road” to progress. “There was definitely a time period we just didn't know (how we were) going do that model,” he said of ChatGPT 4. But all of it, he said, seemed to be guided by something positive. “We have a lot of people here who are excited to build AGI,” he said. “That’s a very motivating thing. But there's a famous quote … it’s something like… the spirit of it is (like) ‘I never pray and ask for God to be on my side. … I pray and hope to be on God's side.’ And there is something about betting on deep learning that feels like being on the side of the angels, and you kind of just- eventually, it just seems to work out.” In discussing the heavy decisions that confront leaders in these times of change, he mentioned a large number of what he called “51-49” decisions, close decisions with little clear favor, that tend to wind up on his plate. Altman mused about how to crowdsource input from a number of different people, and why that has worked well for him over the years. On the issue of semiconductor supply chains, Altman said he’s worried, but it’s not his top worry, although he characterized this hardware issue as being “in the top 10% of all top worries.” The Biggest Worry in Tech: Also: Applications, and Predictions His top worry? The generalized complexity of systems. “It feels like it's all going to work out, but it feels like a very complex system,” he said. In terms of good future use cases, Altman suggested AI-enabled verticals, such as tutors, and the full human potential of applications, like an AI that “understands your whole life.” And then there was his prediction for the future: “In five years, it looks like we have an unbelievable rapid rate of improvement in technology itself,” he said. “You know, people are like, ‘man, the AGI moment came and went,’ … and we're discovering all this new stuff, both in AI research, and also about all the rest of science. … And then the second part of the prediction is that society itself actually changes surprisingly little. An example of this would be that if you asked people five years ago if computers would pass the Turing test, they would say ‘no.’ And then if you said, ‘Well, what if an Oracle (told us this would happen, they would say) ‘it would somehow be this crazy breath-taking change for society.’ And we did kind of satisfy the Turing test in a manner of speaking, of course, and society didn’t change that much. It just sort of went whooshing by. And that's kind of the example of what I expect to keep happening, which is progress, scientific progress keeps going, and it will outperform all expectations in society, in a way that I think is good and healthy.” That’s a lot of the highlights of this timely interview on models, on OpenAI’s progress, and the progress of the industry, as we wait for the full rollout of o1, and the release of Orion, probably next year, and everything else that has techheads all a-twitter. Meanwhile, we saw an o1 leak this week that brings new reasoning models more into the forefront of human thought, where, assuredly, they will stay for quite a while. The other big news right now is that a lot of these companies seem to have delayed any more rollouts until Americans visit the polls. And that’s happening. Watch this space.", highlights=None, highlight_scores=None, summary=None), Result(url='https://www.businessinsider.com/inside-mind-of-sam-altman-openai-ceo-worldview-interviews-writing-2024-11', id='https://www.businessinsider.com/inside-mind-of-sam-altman-openai-ceo-worldview-interviews-writing-2024-11', title='Inside the Mind of Sam Altman: How the OpenAI CEO Sees the World', score=None, published_date='2024-12-08T10:00:02.000Z', author='Adam Rogers', image='https://i.insider.com/67223a41a0a0cc14f224e48b?width=1200&format=jpeg', favicon='https://www.businessinsider.com/public/assets/BI/US/favicons/favicon-32x32.png?v=2023-11', subpages=None, extras=None, text='From psychedelics to Rachmaninoff: how the CEO of OpenAI sees the world Alastair Grant/AP; Rebecca Zisser/BI Read in app It\'s been decades since a titan of tech became a pop-culture icon. Steve Jobs stepped out on stage in his black turtleneck in 1998. Elon Musk set his sights on Mars in 2002. Mark Zuckerberg emerged from his Harvard dorm room in 2004. And now, after years of stasis in Silicon Valley, we have Sam Altman . The cofounder and CEO of the chatbot pioneer OpenAI stands at the center of what\'s shaping up to be a trillion-dollar restructuring of the global economy. His image — boyishly earnest, chronically monotonic, carelessly coiffed — is a throwback to the low-charisma, high-intelligence nerd kings of Silicon Valley\'s glory days . And as with his mythic-hero predecessors, people are hanging on his every word. In September, when Altman went on a podcast called " How I Write " and mentioned his love of pens from Uniball and Muji, his genius life hack ignited the internet. "OpenAI\'s CEO only uses 2 types of pens to take notes," Fortune reported — with a video of the podcast. It\'s easy to laugh at our desperation for crumbs of wisdom from Altman\'s table. But the notability of Altman\'s notetaking ability is a meaningful signifier. His ideas on productivity and entrepreneurship — not to mention everything from his take on science fiction to his choice of vitamins — have become salient not just to the worlds of tech and business, but to the broader culture. The new mayor-elect of San Francisco, for instance, put Altman on his transition team . And have you noticed that a lot of tech bros are starting to wear sweaters with the sleeves rolled up? A Jobsian singularity could be upon us. But the attention to Altman\'s pen preferences raises a larger question: What does his mindset ultimately mean for the rest of us? How will the way he thinks shape the world we live in? To answer that question, I\'ve spent weeks taking a Talmudic dive into the Gospel According to Sam Altman. I\'ve pored over hundreds of thousands of words he\'s uttered in blog posts, conference speeches, and classroom appearances. I\'ve dipped into a decade\'s worth of interviews he\'s given — maybe 40 hours or so. I won\'t claim to have taken anything more than a core sample of the vast Altmanomicon. But immersing myself in his public pronouncements has given me a new appreciation for what makes Altman tick. The innovative god-kings of the past were rule-breaking disruptors or destroyers of genres. The new guy, by contrast, represents the apotheosis of what his predecessors wrought. Distill the past three decades of tech culture and business practice into a super-soldier serum, inject it into the nearest scrawny, pale arm, and you get Sam Altman — Captain Silicon Valley, defender of the faith. Altman at a Times Square event in 2006, during the early days of Loopt. The startup failed — but it immersed Altman in the Silicon Valley mindset. Jason Kempin/FilmMagic via Getty Images. Let\'s start with the vibes. Listening to Altman for hours on end, I came away thinking that he seems like a pretty nice guy. Unlike Jobs, who bestrode the stage at Apple events dropping one-more-things like a modern-day Prometheus, Altman doesn\'t spew ego everywhere. In interviews, he comes across as confident but laid back. He often starts his sentences with "so," his affect as flat as his native Midwest. He also has a Midwesterner\'s amiability, somehow seeming to agree with the premise of almost any question, no matter how idiotic. When Joe Rogan asked Altman whether he thinks AI would one day be able, via brain chips, to edit human personalities to be less macho, Altman not only let it ride, he turned the interview around and started asking Rogan questions about himself. Another contrast with the tech gurus of yore: Altman says he doesn\'t care much about money. His surprise firing at OpenAI, he says, taught him to value his loving relationships — a "recompilation of values" that was "a blessing in disguise." In the spring, Altman told a Stanford entrepreneur class that his money-, power-, and status-seeking phases were all in the rearview. "At this point," Altman said, "I feel driven by wanting to do something useful and interesting." Altman is even looking into universal basic income — giving money to everyone, straight out, no strings attached. That\'s partly because he thinks artificial intelligence will make paying jobs as rare as coelacanths. But it\'s also a product of unusual self-awareness. Altman, famously, was in the "first class" of Y Combinator, Silicon Valley\'s ur-incubator of tech startups. Now that he\'s succeeded, he recalls that grant money as a kind of UBI — a gift that he says prevented him from ending up at Goldman Sachs. Rare is the colossus of industry who acknowledges that anyone other than himself tugged on those bootstraps. By 2014, Altman was running Y Combinator, where he became one of tech\'s most influential evangelists. Brian Ach/Getty Images for TechCrunch Altman\'s seeming rejection of wealth is a key element of his mythos. On a recent appearance on the " All-In" podcast , the hosts questioned Altman\'s lack of equity in OpenAI, saying it made him seem less trustworthy — no skin in the game. Altman explained that the company was set up as a nonprofit, so equity wasn\'t a thing. He really wished he\'d gotten some, he added, if only to stop the endless stream of questions about his lack of equity. Charming! (Under Altman\'s watch, OpenAI is shifting to a for-profit model.) Altman didn\'t get where he is because he made a fortune in tech. Y Combinator, where he started out, was the launchpad for monsters like Reddit, Dropbox, Airbnb, Stripe, DoorDash, and dozens of other companies you\'ve never heard of, because they never got big. Loopt, the company Altman founded at 20 years old, was in the second category. Yet despite that, the Y Combinator cofounder Paul Graham named him president of the incubator in 2014. It wasn\'t because of what Altman had achieved — Loopt burned through $30 million before it folded — but because he embodies two key Silicon Valley mindsets. First, he emphasizes the need for founders to express absolute certainty in themselves, no matter what anyone says. And second, he believes that scale and growth can solve every problem. To Altman, those two tenets aren\'t just the way to launch a successful startup — they\'re the twin turbines that power all societal progress. More than any of his predecessors, he openly preaches Silicon Valley\'s almost religious belief in certainty and scale. They are the key to his mindset — and maybe to our AI-enmeshed future. In 2020, Altman wrote a blog post called " The Strength of Being Misunderstood ." It was primarily a paean to the idea of believing you are right about everything. Altman suggested that people spend too much time worrying about what other people think about them, and should instead "trade being short-term low-status for being long-term high-status." Being misunderstood by most people, he went on, is actually a strength, not a weakness — "as long as you are right." For Altman, being right is not the same thing as being good. When he talks about who the best founders are and what makes a successful business, he doesn\'t seem to think it matters what their products actually do or how they affect the world. Back in 2015, Altman told Kara Swisher that Y Combinator didn\'t really care about the specific pitches it funded — the founders just needed to have "raw intelligence." Their actual ideas? Not so important. "The ideas are so malleable," Altman said. "Are these founders determined, are they passionate about this, do they seem committed to it, have they really thought about all the issues they\'re likely to face, are they good communicators?" Altman wasn\'t betting on their ideas — he was betting on their ability to sell their ideas, even if they were bad. That\'s one of the reasons, he says, that Y Combinator didn\'t have a coworking space — so there was no place for people to tell each other that their ideas sucked. "There are founders who don\'t take no for an answer and founders who bend the world to their will," Altman told a startups class at Stanford , "and those are the ones who are in the fund." What really matters, he added, is that founders "have the courage of your convictions to keep doing this unpopular thing because you understand the way the world is going in a way that other people don\'t." One example Altman cites is Airbnb, whose founders hit on their big idea when they maxed out their credit cards trying to start a different company and wanted to rent out a spare room for extra cash. He also derives his disdain for self-doubt from Elon Musk, who once gave him a tour of SpaceX. "The thing that sticks in memory," Altman wrote in 2019 , "was the look of absolute certainty on his face when he talked about sending large rockets to Mars. I left thinking \'huh, so that\'s the benchmark for what conviction looks like.\'" This, Altman says, is why founding a startup is something people should do when they\'re young — because it requires turning work-life balance into a pile of radioactive slag. "Have almost too much self-belief," he writes. "Almost to the point of delusion." So if Altman believes that certainty in an idea is more important than the idea itself, how does he measure success? What determines whether a founder turns out to be "right," as he puts it? The answer, for Altman, is scale. You start a company, and that company winds up with lots of users and makes a lot of money. A good idea is one that scales, and scaling is what makes an idea good. For Altman, this isn\'t just a business model. It\'s a philosophy. "You get truly rich by owning things that increase rapidly in value," he wrote in a 2019 blog post called " How to Be Successful ." It doesn\'t matter what — real estate, natural resources, equity in a business. And the way to make things increase rapidly in value is "by making things people want at scale." In Altman\'s view, big growth isn\'t just a way to keep investors happy. It\'s the evidence that confirms one\'s unwavering belief in the idea. Artificial intelligence itself, of course, is based on scale — on the ever-expanding data that AI feeds on. Altman said at a conference that OpenAI\'s models would double or triple in size every year, which he took to mean they\'ll eventually reach full sentience. To him, that just goes to show the potency of scale as a concept — it has the ability to imbue a machine with true intelligence. "It feels to me like we just stumbled on a new fact of nature or science or whatever you want to call it," Altman said on "All-In." "I don\'t believe this literally, but it\'s like a spiritual point — that intelligence is an emergent property of matter, and that\'s like a rule of physics or something." Altman says he doesn\'t actually know how intelligent, or superintelligent, AI will get — or what it will think when it starts thinking. But he believes that scale will provide the answers. "We will hit limits, but we don\'t know where those will be," he said on Ezra Klein\'s podcast . "We\'ll also discover new things that are really powerful. We don\'t know what those will be either." You just trust that the exponential growth curves will take you somewhere you want to go. In all the recordings and writings I\'ve sampled, Altman speaks only rarely about things he likes outside startups and AI. In the canon I find few books, no movies, little visual art, not much food or drink. Asked what his favorite fictional utopias are, Altman mentions "Star Trek" and the Isaac Asimov short story "The Last Question," which is about an artificial intelligence ascending to godhood over eons and creating a new universe. Back in 2015, he said "The Martian," the tale of a marooned astronaut hacking his way back to Earth, was eighth on his stack of bedside books. Altman has also praised the Culture series by Iain Banks, about a far-future galaxy of abundance and space communism, where humans and AIs live together in harmony. Altman in 2018. Beyond startups and AI, he rarely speaks about things he likes. Drew Angerer/Getty Images Fiction, to Altman, appears to hold no especially mysterious human element of creativity. He once acknowledged that the latest version of ChatGPT wasn\'t very good at storytelling, but he thought it was going to get much better. "You show it a bunch of examples of what makes a good story and what makes a bad story, which I don\'t think is magic," he said. "I think we really understand that well now. We just haven\'t tried to do that." It\'s also not clear to me whether Altman listens to music — at least not for pleasure. On the " Life in Seven Songs " podcast, most of the favorite songs Altman cited were from his high school and college days. But his top pick was Rachmaninoff\'s Piano Concerto No. 2. "This became something I started listening to when I worked," he said. "It\'s a great level of excitement, but it\'s not distracting. You can listen to it very loudly and very quietly." Music can be great, but it shouldn\'t get in the way of productivity. For Altman, even drug use isn\'t recreational. In 2016, a "New Yorker" profile described Altman as nervous to the point of hypochondria. He would telephone his mother — a physician — to ask whether a headache might be cancer. He once wrote that he "used to hate criticism of any sort and actively avoided it," and he has said he used to be "a very anxious and unhappy person." He relied on caffeine to be productive, and used marijuana to sleep. Now, though? He\'s "very calm." He doesn\'t sweat criticism anymore. If that sounds like the positive outcome of years of therapy, well — sort of. Last summer, Altman told Joe Rogan that an experience with "psychedelic therapy" had been one of the most important turning points in his life. "I struggled with all kinds of anxiety and other negative things," he said, "and to watch all of that go away — I came back a totally different person, and I was like, \'I have been lied to.\'" He went into more detail on the Songs podcast in September. "I think psychedelic experiences can be totally incredible, and the ones that have been totally life-changing for me have been the ones where you go travel to a guide, and it\'s psychedelic medicine," he said. As for his anxiety, "if you had told me a one-weekend-long retreat in Mexico was going to change that, I would have said, \'absolutely not.\'" Psychedelics were just another life hack to resolve emotional turmoil. (I reached out to Altman and offered to discuss my observations with him, in the hopes he\'d correct any places where he felt I was misreading him. He declined.) AI started attracting mainstream attention only in the past couple of years, but the field is much older than that — and Altman cofounded OpenAI nearly a decade ago. So he\'s been asked what "artificial general intelligence" is and when we\'re going to get it so often, and for so long, that his answers often include a whiff of frustration. These days, he says that AGI is when the machine is as smart as the median human — choose your own value for "smart" and "median" there — and "superintelligence" is when it\'s smarter than all of us meatbags squished together. But ask him what AI is for, and he\'s a lot less certain-seeming today than he used to be. As the CEO of OpenAI, Altman says that "superintelligence" — the moment machines become smarter than their human masters — is only "thousands of days" away. Justin Sullivan/Getty Images There\'s the ability to write code, sure. Altman also says AI will someday be a tutor as good as those available to rich people. It\'ll do consultations on medical issues, maybe help with "productivity" (by which he seems to mean the speed at which a person can learn something, versus having to look it up). And he said scientists had been emailing him to say that the latest versio of ChatGPT has increased the rate at which they can do "great science" (by which he seems to mean the speed at which they can run evaluations of possible new drugs). And what would you or I do with a superintelligent buddy? "What if everybody in the world had a really competent company of 10,000 employees?" Altman once asked . "What would we be able to create for each other?" He was being rhetorical — but whatever the answer turns out to be, he\'s sure it will be worth the tremendous cost in energy and resources it will take to achieve it. As OpenAI-type services expand and proliferate, he says, "the marginal cost of intelligence and the marginal cost of energy are going to trend rapidly toward zero." He has recently speculated that intelligence will be more valuable than money, and that instead of universal basic income, we should give people universal basic compute — which is to say, free access to AI. In Altman\'s estimation, not knowing what AI will do doesn\'t mean we shouldn\'t go ahead and restructure all of society to serve its needs. And besides, AI won\'t take long to give us the answer. Superintelligence, Altman has promised , is only "thousands of days" away — half a decade, at minimum. But, he says, the intelligent machine that emerges probably won\'t be an LLM chatbot. It will use an entirely different technical architecture that no one, not even OpenAI, has invented yet. That, at its core, reflects an unreconstructed, dot-com-boom mindset. Altman doesn\'t know what the future will bring, but he\'s in a hurry to get there. No matter what you think about AI — productivity multiplier, economic engine, hallucinating plagiarism machine, Skynet — it\'s not hard to imagine what could happen, for good and ill, if you combine Altman\'s absolute certainty with monstrous, unregulated scale. It only took a couple of decades for Silicon Valley to go from bulky computer mainframes to the internet, smartphones, and same-day delivery — along with all the disinformation, political polarization, and generalized anxiety that came with them. But that\'s the kind of ballistic arc of progress that Altman is selling. He is, at heart, an evangelist for the Silicon Valley way. He didn\'t build the tech behind ChatGPT; the most important thing he ever built and scaled is Y Combinator, an old-fashioned business network of human beings. His wealth comes from investments in other people\'s companies. He\'s a macher, not a maker. In a sense, Altman has codified the beliefs and intentions of the tech big shots who preceded him. He\'s just more transparent about it than they were. Did Steve Jobs project utter certainty? Sure. But he didn\'t give interviews about the importance of projecting utter certainty; he just introduced killer laptops, blocked rivals from using his operating system, and built the app store. Jeff Bezos didn\'t found Amazon by telling the public he planned to scale his company to the point that it would pocket 40 cents of every dollar spent online; he just started mailing people books. But Altman is on the record. When he says he\'s absolutely sure ChatGPT will change the world, we know that he thinks CEOs have to say they\'re absolutely sure their product will change the world. His predecessors in Silicon Valley wrote the playbook for Big Tech. Altman is just reading it aloud. He\'s touting a future he hasn\'t built yet, along with the promise that he can will it into existence — whatever it\'ll wind up looking like — one podcast appearance at a time. Adam Rogers is a senior correspondent at Business Insider. Business Insider\'s Discourse stories provide perspectives on the day\'s most pressing issues, informed by analysis, reporting, and expertise. Thanks for signing up! Access your favorite topics in a personalized feed while you\'re on the go. Tech Silicon Valley OpenAI More...', highlights=None, highlight_scores=None, summary=None)]Sam Altman, born on April 22, 1985, in Chicago, Illinois, is a prominent American entrepreneur recognized for his leadership at OpenAI, where he has served as CEO since 2019. Prior to that, he was president of the startup accelerator Y Combinator from 2014 to 2019, a position that placed him at the forefront of Silicon Valley's innovation ecosystem. Altman is often compared to influential tech figures like Steve Jobs and Bill Gates, particularly for his belief in the potential of artificial general intelligence (AGI) to embody capabilities akin to human cognition. Throughout his career, he has emphasized the mission of making advanced AI tools accessible to the public at minimal costs, as highlighted in a recent blog post where he expressed pride in offering one of the world's best AI models for free through ChatGPT, aiming to benefit billions across the globe[^1][^2].

In recent discussions, including those at OpenAI’s Dev Day, Altman has focused on the rapid advancements in AI technology and its implications for the future. He highlighted the potential for innovative no-code solutions that could revolutionize sectors traditionally reliant on extensive coding skills. He underscored that as AI models advance, companies that embrace these changes could see significant advantages, while those stuck making incremental improvements may find themselves outpaced[^3][^4]. His visionary approach positions him and OpenAI as pivotal players in the ongoing transformation of the global economy, with his personal brand evolving into one reflective of a new wave of tech leadership, bridging the gap between intellect and broader cultural influence[^5].

References
[#] https://blog.samaltman.com/  
[#] https://www.britannica.com/biography/Sam-Altman  
[#] https://blog.samaltman.com/hard-startups  
[#] https://www.forbes.com/sites/johnwerner/2024/11/17/sam-altman-speaks-on-tech-progress/  
[#] https://www.businessinsider.com/inside-mind-of-sam-altman-openai-ceo-worldview-interviews-writing-2024-11